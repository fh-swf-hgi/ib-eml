{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b54ef",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Einführung Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aufgabe zur Logistischen Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aufgabe: Kreditbewertung\n",
    "\n",
    "Der Datensatz *Kreditscoring zur Klassifikation von Kreditnehmern. 2010. Open Data LMU. (https://doi.org/10.5282/ubm/data.23)* beinhaltet 1000 Datensätze, die Vergaben von Privatkrediten beschreiben.\n",
    "Die Spalten beschreiben verschiedene [Merkmale](https://data.ub.uni-muenchen.de/23/1/DETAILS.html), die die Art des Kredits sowie die Eigenschaften der Kunden beschreiben.\n",
    "Beispiele sind Höhe und Laufzeiten der Darlehn sowie das Alter und das Beschäftigungsverhältnis der Kreditnehmer.\n",
    "Die binäre Zielgröße (auch *Dummy Variable* genannt) bildet die Spalte `kredit`.\n",
    "Der Wert `1` bedeutet, dass für den entsprechenden Datenpunkt der Kredit zurückgezahlt wurde.\n",
    "Entsprechend bedeutet `kredit=0`, dass der Kredit nicht ordnungsgemäß zurückgezahlt wurde.\n",
    "\n",
    "Aufgrund dieser Datenbasis kann nun ein System entwickelt werden, dass für eine anstehende Kreditvergabe vorhersagt, ob der Kredit zurückgezalt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir importieren zuerst die Pandas Bibliothek und laden den Datensatz `kredit.csv` in einen `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://github.com/fhswf/datasets/raw/main/kredit.csv\"\n",
    "dfile = \"./kredit.csv\"\n",
    "\n",
    "if not os.path.isfile(dfile):\n",
    "    urllib.request.urlretrieve(url, dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"kredit.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mit `df.info()` und `df.describe()` erhalten wir einige Informationen über den Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wir teilen nun die kompletten Daten in einen Trainings- und einen Test-Datensatz auf.\n",
    "Dazu kann die Methode `train_test_split()` aus dem Modul `sklearn.model_selection` verwendet werden.\n",
    "Der Parameter `test_size` legt den Anteil des Daten im Test-Datensatz fest.\n",
    "Die Aufteilung der Datenpunkte erfolgt zufällig.\n",
    "Falls Sie immer die gleiche Aufteilung vornehmen wollen (damit die Ergebnisse vergleichbar sind) können Sie durch Festlegen des Parameters `random_state` erzwingen, dass immer die gleichen Folgen von Zufallszahlen erzeugt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr().kredit.abs().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wenn Sie testen wollen, wie gut das Modell mit einer Auswahl der Merkmale funktioniert, können Sie die Spalten im Datensatz entsprechend einschränken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features = [\"sparkont\",\"rate\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features],df.iloc[:,0],test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Für die Modellbildung verwenden wir nun wieder `sklearn`, diesmal mit einem logistischen Regressionsmodell.\n",
    "\n",
    "Die Modellparameter können über die Attribute `intercept_` und `coef_` abgerufen werden.\n",
    "Üblicherweise interessieren den Programmierer diese Werte nicht.\n",
    "die Schätzung für einen neuen Datenpunkt kann ja ganz einfach mit der Funktion `predict()` berechnet werden.\n",
    "Für uns sind die Informationen allerdings interessant, wenn wir die Methode `fit()` händisch nachprogrammieren wollen und so die jeweiligen gelerneten Modellparameter miteinander vergleichen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.intercept_,  model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nachdem Wir das Modell mit den Trainingsdaten trainiert haben, verwenden wir den Testdatensatz um die Qualität des Modells zu bewerten.\n",
    "Eine Vorhersagegenauigkeit von 66,6% bedeutet, dass für 2 von 3 Krediten korrekt vorhergesagt werden konnte, ob ein Kredit vom Bankkunden ordnungsgemäß zurückgezahlt wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = model.predict(X_test)\n",
    "acc_train = np.sum((y_pred==y_test)*1)/len(y_test)\n",
    "print(\"Accuracy (Testdaten): %.2f%%\" % (acc_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** **Verwenden nun alle Merkmale des Datensatzes in einem neuen Modell und berechnen Sie die *Classification Accuracy* für dieses Modell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** **Verwenden Sie die oben beschrieben Techniken, um Entscheidungsgrenzen für einen zufällig erzeugten Datensatz zu berechnen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# generating two-class dataset\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, center_box = (-5, 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Teilen Sie den Datensatz auf (70% Training, 30% Test):\n",
    "- `X_train`: training dataset\n",
    "- `X_test`: test dataset\n",
    "- `y_train`: training labels\n",
    "- `y_test`: test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7c0c8cf666d3b5c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = [None]*4\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8818e07d53ed936b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert np.vstack((X_train, X_test)) in X and np.hstack((y_train, y_test)) in y\n",
    "assert y_train.size/y.size == 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Verwenden Sie die *sklearn*-Klasse `LogisticRegression` um ein Modell für den Datensatz zu bilden. Trainieren Sie das Modell mit den oben festgelegten Trainingsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12524a6611e42cf3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c2da293e49378c98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert type(logreg) == LogisticRegression\n",
    "assert logreg.intercept_, 'Trainieren Sie das Modell mit den Daten!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir visualisieren nun den Datensatz um darzustellen, wie gut unser Modell klassifiziert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting decision regions\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.Spectral)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n",
    "plt.xlabel(r\"$\\Theta_0$\", fontsize=14)\n",
    "plt.ylabel(r\"$\\Theta_1$\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Testen Sie die Vorhersagegenauigkeit (*accuracy*) des Modells mit den Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f17cc003e3def17",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = None\n",
    "acc_test = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"accuracy: %.2f%%\" % acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-35985385625486b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "#----------\n",
    "\n",
    "assert y_pred.shape == y_test.shape\n",
    "### BEGIN HIDDEN TEST\n",
    "assert acc_test == 100-np.sum(np.abs(y_pred-y_test))*100/len(y_pred)\n",
    "### END HIDDEN TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiklassen-Klassifikation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Die logistische Regression liefert uns Ergebnisse für binäre Zielvariablen.\n",
    "Oftmals wollen wir aber mehr als 2 Klassen unterscheiden.\n",
    "\n",
    "Eine Möglichkeit, um Multiklassen-Klassifikation mit logistischen Regression umzusetzen, ist die sogenannte *One-vs-all Klassifikation*.\n",
    "Dabei werden für `n` Klassen `n` separate, binäre Klassifikationsprobleme definiert, bei denen jeweils nur die betrachtete Klasse den Zielwert `1` zugeteilt bekommt, und für alle anderen Klassen der Zielwert `0` angenommen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn unterstüzt Multiklassen-Klassifikation in der Klasse `LogisticRegression` über den Parameter `multi_class`.\n",
    "Setzt man : `multi_class=\"ovr\"` führt die Funktion `fit` je eine logistische Regression für jedes Label nach dem *one-vs-all* (oder auch *one-vs-rest*, ovr) Prinzip aus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In der folgenden Code-Zelle erzeugen wir 3 Punktwolken.\n",
    "Alle Punkte einer \"Wolke\" sollen zu einer bestimmten Klasse gehören."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=100, centers=3, n_features=2, random_state=10, cluster_std=2.5)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "markers = {0:'o', 1:'x', 2:'^'}\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, marker=markers[key], color=colors[key])\n",
    "    \n",
    "plt.legend(loc='upper right', prop={'size': 12})\n",
    "plt.savefig(\"LogistischeRegression20.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Nun wenden wir ein logistisches Regressionsmodell auf die Datenbasis an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',multi_class=\"ovr\")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.intercept_ , model.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Der folgende Graph zeigt die Entscheidungsgrenzen für das Klassifikationsmodell.\n",
    "Alle Punkte innerhalb eines Bereiches werden der jeweiligen Klasse zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "xx = np.linspace(X_train[:,0].min()-1, X_train[:,0].max()+1, 300)\n",
    "yy = np.linspace(X_train[:,1].min()-1, X_train[:,1].max()+1, 300)\n",
    "XX, YY = np.meshgrid(xx,yy)\n",
    "ZZ = model.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "ZZ = ZZ.reshape(XX.shape)\n",
    "\n",
    "yyy = model.intercept_[0] + model.coef_[0][0]*xx + model.coef_[0][1]*yy\n",
    "\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "markers = {0:'o', 1:'x', 2:'^'}\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "#plt.pcolormesh(XX, YY, ZZ, cmap=plt.cm.Set3)\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, marker=markers[key], color=colors[key])\n",
    "    \n",
    "\n",
    "plt.contour(XX, YY, ZZ, cmap=plt.cm.Blues)\n",
    "plt.legend(loc='upper right', prop={'size': 12})\n",
    "plt.savefig(\"LogistischeRegression21.png\",transparent=True, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionale Aufgabe: Ziffernerkennung\n",
    "\n",
    "Im folgenden Beispiel laden wir einen Datensatz, in dem handschriftliche Ziffern mit einer Auflösung von 8x8 Pixeln als Graustufenbilder abgelegt sind. Die Pixel sind dabei als eindimensionales Array gespeichert und daher vor dem Anzeigen in ein 8x8 Array umgeformt werden.\n",
    "\n",
    "Zunächst führen wir eine binäre Klassifikation durch. Dazu laden wir nur die Bilder der Nullen und Einsen in unseren Datensatz `X` (Pixel) und `y` (Label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "digits = load_digits(as_frame=True).frame\n",
    "digits = digits[np.logical_or(digits.target == 0, digits.target == 1)]\n",
    "X = digits.drop(\"target\", axis=1).values\n",
    "y = digits.target.values\n",
    "\n",
    "\n",
    "def plot_digits(X,y):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(8,4))\n",
    "    for i in range(10):\n",
    "        idx = randint(0,X.shape[0]-1)\n",
    "        ax = axes[i//5, i%5]\n",
    "        ax.imshow(X[idx].reshape(8,8), cmap='gray')\n",
    "        ax.set_title(f'Klasse {y[idx]}')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_digits(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie immer teilen wir auch hier den Datensatz auf, um Testdaten vorzubehalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wenden wir die Logistische Regression an, um die Ziffen zu klassifizieren. Die `score`-Methode liefert uns die *Accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Führen Sie die Klassikation nun erneut durch, aber mit den Ziffern 1 und 8. Ist das Ergebnis immer noch so gut?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Führen Sie nun eine Multiklassen-Klassikation für die Ziffern von 0 bis 9 durch und berechnen Sie die Accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Geben Sie die Konfusionsmatrix für das Multiklassen-Modell aus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

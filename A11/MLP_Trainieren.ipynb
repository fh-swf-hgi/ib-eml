{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b54ef",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Einführung Machine Learning\n",
    "### Sommersemester 2023\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f65feb",
   "metadata": {},
   "source": [
    "# MLP Modelle trainieren\n",
    "\n",
    "In diesem Aufgabenblatt geht es darum, MLP-Modelle mit *Scikit-learn* und *Keras* aufzustellen und zu trainieren.\n",
    "Wir verwenden dazu einen synthetischen, nicht-linear-separierbaren Datensatz mit 3 Klassen von Datenpunkten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d8c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_spirals(N=100, classes=2, random_state=0):\n",
    "    np.random.seed(random_state)\n",
    "    X = np.zeros((N*classes,2))\n",
    "    num_train_examples = X.shape[0]\n",
    "    y = np.zeros(N*classes, dtype='uint8')\n",
    "    for j in range(classes):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        r = np.linspace(0.0,1,N) # radius\n",
    "        k = classes+1\n",
    "        t = np.linspace(j*k,(j+1)*k,N) + np.random.randn(N)*0.2 # theta\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "    return X, y\n",
    "\n",
    "N=60\n",
    "classes=3\n",
    "random_state=0\n",
    "\n",
    "X, y = make_spirals(N, classes, random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228652e8",
   "metadata": {},
   "source": [
    "Wie man in folgendem Beispiel sieht, schneidet ein Lineares Modell bei diesen Daten sehr schlecht ab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e922e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decregions_2d(X,y,clf):\n",
    "    '''\n",
    "    Plotte Entscheidungsgrenzen in einem\n",
    "    Datensatz mit zwei Attributen\n",
    "    \n",
    "    Parameter:\n",
    "    X: 2d numpy array der Groesse (m,n)\n",
    "    clf: Klassifizierer mit einer Methoder \"predict\"\n",
    "    '''\n",
    "    cmap = plt.get_cmap('Set1', 3)\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    print(Z.shape)\n",
    "    if Z.ndim>1:\n",
    "        Z = np.argmax(Z, axis=1)\n",
    "        print(Z.shape)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, ec='black', cmap=cmap)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decregions_2d(X_train, y_train, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d783872",
   "metadata": {},
   "source": [
    "**Aufgabe:** Trainieren Sie einen MLPClassifier (aus SKlearn) für den Datensatz. Das MLP soll einen *hidden layer* mit 32 Neuronen besitzen. Welche *Classification Accuracy* Erreicht Ihr Modell für den Trainigsdatensatz? Plotten Sie die Entscheidungsgrenzen Ihres Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e43e1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8460476e9d770622",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957ff19",
   "metadata": {},
   "source": [
    "**Aufgabe:** Bestimmen Sie aus einer Auswahl vorgegebener Hyperparameter die optimale Kombination für einen *MLPClassifier* mithilfe der *GridSearchCV*-Methode. Folgende Parameter sollen zur Auswahl stehen:\n",
    "* `hidden_layer_sizes`: Dieser Parameter gibt die Größe der versteckten Schichten des neuronalen Netzwerks an. Folgende Optionen sollen betrachtet werden:\n",
    " - `(32,)`: Eine versteckte Schicht mit 32 Neuronen.\n",
    " - `(24, 8)`: Zwei versteckte Schichten mit 24 und 8 Neuronen.\n",
    " - `(8, 24)`: Zwei versteckte Schichten mit 8 und 24 Neuronen.\n",
    " - `(16, 8, 8)`: Drei versteckte Schichten mit 16, 8 und 8 Neuronen.\n",
    " - `(8, 16, 8)`: Drei versteckte Schichten mit 8, 16 und 8 Neuronen.\n",
    " - `(16, 8, 4, 4)`: Vier versteckte Schichten mit 16, 8, 4 und 4 Neuronen.\n",
    " \n",
    "\n",
    "* `activation`: Dieser Parameter definiert die Aktivierungsfunktion, die in den Neuronen verwendet wird. Folgende Optionen sollen betrachtet werden:\n",
    " - `tanh`: Tangens hyperbolicus\n",
    " - `relu`: ReLU (Rectified Linear Unit)\n",
    " - `logistic`: Logistische Funktion\n",
    " \n",
    " \n",
    "* `solver`: Dieser Parameter legt den Optimierungsalgorithmus fest, der für das Lernen der Gewichte verwendet wird. Folgende Optionen sollen betrachtet werden:\n",
    " - `sgd`: Stochastic Gradient Descent (SGD) Optimierungsalgorithmus.\n",
    " - `adam`: Adam Optimierungsalgorithmus.\n",
    " \n",
    " \n",
    "* `alpha`: Dieser Parameter bestimmt den Regularisierungsterm, der zur Vermeidung von Überanpassung verwendet wird. Folgende Optionen sollen betrachtet werden:\n",
    " - `0.0001`\n",
    " - `0.01`\n",
    " - `0.05`\n",
    " \n",
    " \n",
    "* `learning_rate`: Dieser Parameter legt die Lernrate fest, die den Gradientenabstieg beeinflusst. Folgende Optionen sollen betrachtet werden:\n",
    " - `constant`: Konstante Lernrate.\n",
    " - `adaptive`: Adaptive Lernrate.\n",
    "\n",
    "\n",
    "Die möglichen Parameter sollen in einem Dictionary `parameter_space` angegben werden. Der Parameter-Name ist dabei jeweils der Key. Der Value ist eine Liste der möglichen Werte.\n",
    "\n",
    "Führen Sie die Suche zuerst für eine maximale Anzahl von 20 Iterationen durch. Ändern sich die optimalen Parameter, wenn Sie 100 und 500 Iterationen lang trainieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34326051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, warnings\n",
    "# Das hier ist gefährlich, weil man so Fehler übersehen kann!!!\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "parameter_space = None\n",
    "clf = None\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "print(f'Die besten Parameter nach {epochs} Epochen:\\n', clf.best_params_)\n",
    "\n",
    "acc = clf.best_estimator_.score(X_test, y_test)\n",
    "print(f'Accuracy nach {epochs} Epochen: {acc}')\n",
    "plot_decregions_2d(X_train, y_train, clf.best_estimator_);\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
